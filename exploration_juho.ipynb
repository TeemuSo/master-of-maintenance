{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ethical-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "discrete-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "differential-tourist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>equipment_id</th>\n",
       "      <th>completion_date</th>\n",
       "      <th>action_recommendation_id</th>\n",
       "      <th>action_recommendation_type</th>\n",
       "      <th>action_recommendation_category</th>\n",
       "      <th>equipment_area</th>\n",
       "      <th>usage_type</th>\n",
       "      <th>speed_category</th>\n",
       "      <th>load_category</th>\n",
       "      <th>floors_category</th>\n",
       "      <th>equipment_category</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b7c775ad-4ebe-4848-9c53-37e7c5658e21</td>\n",
       "      <td>ele0000754</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>ar00000174</td>\n",
       "      <td>art01</td>\n",
       "      <td>arc03</td>\n",
       "      <td>ga00000803</td>\n",
       "      <td>ut012</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>tp006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b177eefd-3946-4949-9699-0a91879350f9</td>\n",
       "      <td>ele0000789</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>ar00000248</td>\n",
       "      <td>art02</td>\n",
       "      <td>arc03</td>\n",
       "      <td>ga00000269</td>\n",
       "      <td>ut005</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>tp001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fc2d568a-c53c-43ef-8871-a49ec22ab3b1</td>\n",
       "      <td>ele0001227</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>ar00000158</td>\n",
       "      <td>art02</td>\n",
       "      <td>arc03</td>\n",
       "      <td>ga00000064</td>\n",
       "      <td>ut011</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>tp006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e645922-1268-4c6b-ae6b-7b1605689cca</td>\n",
       "      <td>ele0001754</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>ar00000105</td>\n",
       "      <td>art01</td>\n",
       "      <td>arc03</td>\n",
       "      <td>ga00000662</td>\n",
       "      <td>ut005</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>tp014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b44f10b1-9238-44db-8f0c-2d68e8c015a7</td>\n",
       "      <td>ele0002087</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>ar00000148</td>\n",
       "      <td>art02</td>\n",
       "      <td>arc03</td>\n",
       "      <td>ga00001256</td>\n",
       "      <td>ut011</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>tp013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115470</th>\n",
       "      <td>8eda4489-c34c-4e8a-b592-ad57b5fd842a</td>\n",
       "      <td>ele0029759</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>ar00000124</td>\n",
       "      <td>art01</td>\n",
       "      <td>arc03</td>\n",
       "      <td>ga00000817</td>\n",
       "      <td>ut011</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>tp005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115471</th>\n",
       "      <td>0113eba6-6928-461a-b994-35a0b2eb9f4e</td>\n",
       "      <td>ele0029783</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>ar00000291</td>\n",
       "      <td>art02</td>\n",
       "      <td>arc01</td>\n",
       "      <td>ga00001027</td>\n",
       "      <td>ut001</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>tp015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115472</th>\n",
       "      <td>c2eab0dc-218a-4a95-ab28-47449f42f660</td>\n",
       "      <td>ele0029785</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>ar00000048</td>\n",
       "      <td>art01</td>\n",
       "      <td>arc02</td>\n",
       "      <td>ga00000355</td>\n",
       "      <td>ut011</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>tp002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115473</th>\n",
       "      <td>c2eab0dc-218a-4a95-ab28-47449f42f660</td>\n",
       "      <td>ele0029785</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>ar00000293</td>\n",
       "      <td>art01</td>\n",
       "      <td>arc02</td>\n",
       "      <td>ga00000355</td>\n",
       "      <td>ut011</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>tp002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115474</th>\n",
       "      <td>6559b358-5f70-44b9-b0ef-17877fe6cd8f</td>\n",
       "      <td>ele0029903</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>ar00000174</td>\n",
       "      <td>art01</td>\n",
       "      <td>arc03</td>\n",
       "      <td>ga00000445</td>\n",
       "      <td>ut007</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>tp006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115475 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     case_id equipment_id completion_date  \\\n",
       "0       b7c775ad-4ebe-4848-9c53-37e7c5658e21   ele0000754      2018-10-03   \n",
       "1       b177eefd-3946-4949-9699-0a91879350f9   ele0000789      2018-10-03   \n",
       "2       fc2d568a-c53c-43ef-8871-a49ec22ab3b1   ele0001227      2018-10-03   \n",
       "3       8e645922-1268-4c6b-ae6b-7b1605689cca   ele0001754      2018-10-03   \n",
       "4       b44f10b1-9238-44db-8f0c-2d68e8c015a7   ele0002087      2018-10-03   \n",
       "...                                      ...          ...             ...   \n",
       "115470  8eda4489-c34c-4e8a-b592-ad57b5fd842a   ele0029759      2020-01-30   \n",
       "115471  0113eba6-6928-461a-b994-35a0b2eb9f4e   ele0029783      2020-01-30   \n",
       "115472  c2eab0dc-218a-4a95-ab28-47449f42f660   ele0029785      2020-01-30   \n",
       "115473  c2eab0dc-218a-4a95-ab28-47449f42f660   ele0029785      2020-01-30   \n",
       "115474  6559b358-5f70-44b9-b0ef-17877fe6cd8f   ele0029903      2020-01-30   \n",
       "\n",
       "       action_recommendation_id action_recommendation_type  \\\n",
       "0                    ar00000174                      art01   \n",
       "1                    ar00000248                      art02   \n",
       "2                    ar00000158                      art02   \n",
       "3                    ar00000105                      art01   \n",
       "4                    ar00000148                      art02   \n",
       "...                         ...                        ...   \n",
       "115470               ar00000124                      art01   \n",
       "115471               ar00000291                      art02   \n",
       "115472               ar00000048                      art01   \n",
       "115473               ar00000293                      art01   \n",
       "115474               ar00000174                      art01   \n",
       "\n",
       "       action_recommendation_category equipment_area usage_type  \\\n",
       "0                               arc03     ga00000803      ut012   \n",
       "1                               arc03     ga00000269      ut005   \n",
       "2                               arc03     ga00000064      ut011   \n",
       "3                               arc03     ga00000662      ut005   \n",
       "4                               arc03     ga00001256      ut011   \n",
       "...                               ...            ...        ...   \n",
       "115470                          arc03     ga00000817      ut011   \n",
       "115471                          arc01     ga00001027      ut001   \n",
       "115472                          arc02     ga00000355      ut011   \n",
       "115473                          arc02     ga00000355      ut011   \n",
       "115474                          arc03     ga00000445      ut007   \n",
       "\n",
       "        speed_category  load_category  floors_category equipment_category  \\\n",
       "0                    7              6                8              tp006   \n",
       "1                    4              6                2              tp001   \n",
       "2                    6              6                7              tp006   \n",
       "3                    8              7                8              tp014   \n",
       "4                    7              6                8              tp013   \n",
       "...                ...            ...              ...                ...   \n",
       "115470               6              7                8              tp005   \n",
       "115471               4              3                1              tp015   \n",
       "115472               2              1                4              tp002   \n",
       "115473               2              1                4              tp002   \n",
       "115474               6              4                8              tp006   \n",
       "\n",
       "        feedback  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "...          ...  \n",
       "115470         1  \n",
       "115471         1  \n",
       "115472         1  \n",
       "115473         1  \n",
       "115474         1  \n",
       "\n",
       "[115475 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cooperative-orbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 3 6\n"
     ]
    }
   ],
   "source": [
    "train_data[train_data['feedback'] == 0]\n",
    "n_ids = train_data['action_recommendation_id'].nunique()\n",
    "n_types = train_data['action_recommendation_type'].nunique()\n",
    "n_categories = train_data['action_recommendation_category'].nunique()\n",
    "\n",
    "print(n_ids, n_types, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hourly-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of feedback in train data: 0.88\n",
      "case_id: 73945\n",
      "equipment_id: 30000\n",
      "completion_date: 466\n",
      "action_recommendation_id: 295\n",
      "action_recommendation_type: 3\n",
      "action_recommendation_category: 6\n",
      "equipment_area: 1285\n",
      "usage_type: 13\n",
      "speed_category: 8\n",
      "load_category: 8\n",
      "floors_category: 8\n",
      "equipment_category: 20\n",
      "feedback: 2\n"
     ]
    }
   ],
   "source": [
    "global_mean_train = train_data['feedback'].mean()\n",
    "print(f'Mean of feedback in train data: {global_mean_train:.2f}')\n",
    "\n",
    "train_data['equipment_area'].nunique()\n",
    "# plt.hist(train_data['equipment_area'])\n",
    "# plt.show()\n",
    "for column in train_data.columns:\n",
    "    print(f'{column}: {train_data[column].nunique()}')\n",
    "#     train_data[column].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "exotic-current",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-9592d1d1776c>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-9592d1d1776c>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    not_type_cats = train_data[train_data['action_recommendation_type'] == train_data.loc[train_data.loc['action_recommendation_type'] != type, 'action_recommendation_category'].duplicated()]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for category in train_data['action_recommendation_category'].unique():\n",
    "    print(f'\\n{category}')\n",
    "    cat_ids = train_data.loc[train_data['action_recommendation_category'] == category, 'action_recommendation_id'].unique()\n",
    "    not_cat_ids = train_data.loc[train_data['action_recommendation_category'] != category, 'action_recommendation_id'].unique()\n",
    "    print(np.intersect1d(cat_ids, not_cat_ids))\n",
    "    \n",
    "for type in train_data['action_recommendation_type'].unique():\n",
    "    print(f'\\n{type}')\n",
    "    type_ids = train_data.loc[train_data['action_recommendation_type'] == type, 'action_recommendation_id'].unique()\n",
    "    not_type_ids = train_data.loc[train_data['action_recommendation_type'] != type, 'action_recommendation_id'].unique()\n",
    "    print(np.intersect1d(type_ids, not_type_ids))\n",
    "    \n",
    "for type in train_data['action_recommendation_type'].unique():\n",
    "    print(f'\\n{type}')\n",
    "    type_cats = train_data[train_data['action_recommendation_type'] == train_data.loc[train_data.loc[train_data['action_recommendation_type'] == type, 'action_recommendation_category'].duplicated()]\n",
    "    not_type_cats = train_data[train_data['action_recommendation_type'] == train_data.loc[train_data.loc['action_recommendation_type'] != type, 'action_recommendation_category'].duplicated()]\n",
    "    display(type_cats)\n",
    "    intersection_idx = type_cats.isin(not_type_cats)\n",
    "    display(train_data[['action_recommendation_type', 'action_recommendation_category']].loc[intersection_idx])\n",
    "#     print(np.intersect1d(type_ids, not_type_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "central-yellow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101351"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def target_encode_mean(df: pd.DataFrame, column: str, min_category_size: int, global_mean) -> (pd.DataFrame, pd.Series):\n",
    "    \"\"\"\n",
    "    Converts a categorical variable to a target encoded variable based on the means of the target variable.\n",
    "    \"\"\"\n",
    "    # NaN cannot be used as a key so we have to convert NaNs to string\n",
    "    df[column].replace(np.nan, 'NaN', inplace=True)\n",
    "    mean_column = f'{column}_mean'\n",
    "    counts_distinct = df[column].value_counts()\n",
    "    counts = df[column].map(counts_distinct)\n",
    "    mean_mappings = df.groupby(column).mean()['delivery_time']\n",
    "    df[mean_column] = df[column].map(mean_mappings)\n",
    "    df.loc[counts < min_category_size, mean_column] = global_mean\n",
    "    return df, mean_mappings\n",
    "\n",
    "def build_features(df: pd.DataFrame):\n",
    "    categorical_features = [\n",
    "        'action_recommendation_id',\n",
    "        'action_recommendation_type',\n",
    "        'action_recommendation_category',\n",
    "        'equipment_area',\n",
    "        'usage_type',\n",
    "        'speed_category',\n",
    "        \n",
    "    ]\n",
    "#     In our specific dataset, all of the columns are categorical\n",
    "    categorical_columns = df.columns\n",
    "    # Category must include at least this many samples. If not, then it's encoded to global mean delivery time.\n",
    "    min_category_size = 100\n",
    "    for feature in categorical_columns_to_use:\n",
    "        df = target_encode_mean(df, feature, min_category_size, global_mean)\n",
    "        \n",
    "    target = df['feedback']\n",
    "    features = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brazilian-incentive",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0d9674180285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_write\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocessed_data_from_disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Optimizes hyper-parameters for NGBoost using Optuna.\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from dotenv import load_dotenv\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.distns import Bernoulli\n",
    "from ngboost.scores import LogScore\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import click\n",
    "from time import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class NgbOptimizer:\n",
    "\n",
    "    def __init__(self, study_name: str, X_train, y_train):\n",
    "        # We use only the train set in optimization. Later we split it to train and validation in each iteration.\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        sampler = optuna.samplers.NSGAIISampler()\n",
    "        pruner = optuna.pruners.SuccessiveHalvingPruner()\n",
    "        self.study = optuna.create_study(storage=os.environ['OPTUNA_DB_URL'], study_name=study_name,\n",
    "                                         direction='minimize', load_if_exists=True, sampler=sampler, pruner=pruner)\n",
    "\n",
    "    def optimize(self):\n",
    "        self.study.optimize(self._objective, n_trials=10000, catch=(ValueError,), gc_after_trial=True)\n",
    "\n",
    "    def _objective(self, trial: optuna.Trial):\n",
    "        print('Splitting train and validation data.')\n",
    "        start_time = time()\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.X_train, self.y_train)\n",
    "        print(f'Took {time()-start_time:.2f} s.')\n",
    "        tree_parameters = {\n",
    "            'criterion': 'friedman_mse',    # No clue if better than MSE or MAE\n",
    "            'splitter': 'best',\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 1000),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 1000),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 1000),\n",
    "            'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
    "            'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2, 10000),\n",
    "            'min_impurity_decrease': 0,     # We use other parameters (depth, number of leaves etc.) for regularization\n",
    "            'ccp_alpha': 0,                 # We use other parameters (depth, number of leaves etc.) for regularization\n",
    "        }\n",
    "        print('Initializing base learner.')\n",
    "        start_time = time()\n",
    "        tree_learner = DecisionTreeClassifier(**tree_parameters)\n",
    "        print(f'Took {time()-start_time:.2f} s.')\n",
    "        ngb_parameters = {\n",
    "            'Dist': Bernoulli,\n",
    "            'Score': LogScore,\n",
    "            'Base': tree_learner,\n",
    "            'natural_gradient': True,\n",
    "            'n_estimators': 500,\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1),\n",
    "            'minibatch_frac': trial.suggest_uniform('minibatch_frac', 1e-5, 1),\n",
    "            'col_sample': trial.suggest_uniform('col_sample', 1e-5, 1),\n",
    "            'tol': 0,\n",
    "            'verbose_eval': 1,\n",
    "        }\n",
    "        trial.set_user_attr('tol', 0)\n",
    "        early_stopping_rounds = trial.suggest_int('early_stopping_rounds', 1, 20)\n",
    "\n",
    "        # We define val_loss_monitor so that it reports the validation score to the trial and prunes it if necessary.\n",
    "        # Links to help understand what's happening here:\n",
    "        # https://optuna.readthedocs.io/en/v1.0.0/tutorial/pruning.html\n",
    "        # https://github.com/stanfordmlgroup/ngboost/blob/master/ngboost/ngboost.py\n",
    "        # It's pretty gimmicky, but there doesn't seem to be a better way of doing it.\n",
    "        step = -1\n",
    "\n",
    "        def pruning_loss_monitor(manifold, y):\n",
    "            nonlocal step\n",
    "            step += 1\n",
    "            score = manifold.total_score(y)\n",
    "            trial.report(score, step)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "            return score\n",
    "\n",
    "        print(f'Initializing NGBRegressor.')\n",
    "        start_time = time()\n",
    "        ngb = NGBRegressor(**ngb_parameters)\n",
    "        print(f'Took {time()-start_time:.2f} s.')\n",
    "        print(f'Fitting.')\n",
    "        print(f'NGB parameters: {ngb_parameters}')\n",
    "        print(f'Tree parameters: {tree_parameters}')\n",
    "        print(f'early_stopping_rounds: {early_stopping_rounds}')\n",
    "        start_time = time()\n",
    "        ngb.fit(X=X_train, Y=y_train, X_val=X_val, Y_val=y_val, early_stopping_rounds=early_stopping_rounds,\n",
    "                val_loss_monitor=pruning_loss_monitor)\n",
    "        print(f'Took {time()-start_time:.2f} s.')\n",
    "        trial.set_user_attr('n_estimators_actualized', len(ngb.base_models))\n",
    "        log_score = ngb.evals_result['val']['LOGSCORE'][ngb.best_val_loss_itr]\n",
    "        return log_score\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.argument('study-name')\n",
    "def optimize(study_name: str):\n",
    "    NgbOptimizer(study_name).optimize()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    optimize()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
